[General]
globstep = 600
corpus = faq

[Dataset]
datasettag = faq
maxlength = 50
filtervocab = 0
skiplines = True
vocabularysize = 0

[Network]
hiddensize = 256
numlayers = 2
initembeddings = True
embeddingsize = 64
embeddingsource = news_12g_baidubaike_20g_novel_90g_embedding_64.bin

[Training (won't be restored)]
learningrate = 0.002
batchsize = 256
dropout = 0.9

